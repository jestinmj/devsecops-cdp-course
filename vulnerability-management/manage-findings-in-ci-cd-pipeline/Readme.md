Automated Results Upload in GitLab
================================================

Use script(s) to automatically push security findings to Vulnerability Management system from CI/CD
----------------------------------------------------------------

In this scenario, you will learn how to automatically manage security issues using vulnerability management systems like DefectDojo. This hands-on exercise will guide you through the process of integrating security issue management into your workflow, making it easier to track and address potential vulnerabilities in your projects.

A simple CI/CD pipeline
----------

Considering your DevOps team created a simple CI pipeline with the following contents.

```
image: docker:20.10  # To run all jobs in this pipeline, use the latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image that contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

integration:
  stage: integration
  script:
    - echo "This is an integration step"

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
```

We see four jobs in this pipeline, a build job, a test job, a integration job, and a prod job.

As a security engineer, I do not care what they are doing as part of these jobs. Why? Imagine having to learn every build/testing tool used by your DevOps team. It will be a nightmare! Instead, rely on the DevOps team for help.

Let’s log into GitLab using the following details and execute this pipeline.

> access your gitlab

Next, we need to create a CI/CD pipeline by replacing the .gitlab-ci.yml file content with the above CI script. Click on the Edit button to replace the content (use Control+A and Control+V).

Save changes to the file using the Commit changes button.


Verify the pipeline run
----------

As soon as a change is made to the repository, the pipeline starts executing the jobs.

We can see the results of this pipeline by visiting https://gitlab-ce-XqiHnDZ0.lab.practical-devsecops.training/root/django-nv/pipelines.

Click on the appropriate job name to see the output.

This exercise uses three machines behind the scenes, you already know about Gitlab CI. You will find details about the other two machines below.

Machine(s) access
----------
- Dojo URL : dojo-XqiHnDZ0.lab.practical-devsecops.training/
- Username: root
- Password: pdso-training
> 
- Prod URL : prod-XqiHnDZ0.lab.practical-devsecops.training
- Username: admin
- Password: admin

> You will use the prod machine in the next exercise (not the below one).

Upload script
----------

You can use the upload-results.py script from [https://gitlab.practical-devsecops.training/-/snippets/28/raw](https://gitlab.practical-devsecops.training/-/snippets/28/raw)

Exercise
----------

We will use the bandit tool to scan a repository for security issues and upload the tool’s output to DefectDojo in CI/CD pipeline.

1. Read the [bandit documentation](https://github.com/PyCQA/bandit/tree/master/bandit)
2. Embed bandit in build stage and save the output as JSON file
3. Where should you upload the upload-results.py file for the fully automated pipeline to work?
4. Remember to follow all best practices while adding the baseline scan to CI/CD pipeline

Once you are done, please do not forget to share the pipeline script with our staff.

> Please try to do this exercise without looking at the solution on the next page.

Embed Bandit and upload script in CI/CD pipeline
----------

As discussed in the Static Analysis using Bandit exercise, we can embed the Bandit tool in our CI/CD pipeline. However, you need to run the command manually before you embed this SAST tool in the pipeline.

```
image: docker:20.10  # To run all jobs in this pipeline, use the latest docker image

services:
  - docker:dind       # To run all jobs in this pipeline, use a docker image that contains a docker daemon running inside (dind - docker in docker). Reference: https://forum.gitlab.com/t/why-services-docker-dind-is-needed-while-already-having-image-docker/43534

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env                       # Create a virtual environment for the python application
   - source env/bin/activate              # Activate the virtual environment
   - pip install -r requirements.txt      # Install the required third party packages as defined in requirements.txt
   - python manage.py check               # Run checks to ensure the application is working fine

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

sast:
  stage: build
  before_script:
    - apk add py-pip py-requests
  script:
    - docker pull hysnsec/bandit  # Download bandit docker container
    - docker run --user $(id -u):$(id -g) -v $(pwd):/src --rm hysnsec/bandit -r /src -f json -o /src/bandit-output.json
  after_script:
    - python3 upload-results.py --host $DOJO_HOST --api_key $DOJO_API_TOKEN --engagement_id 1 --product_id 1 --lead_id 1 --environment "Production" --result_file bandit-output.json --scanner "Bandit Scan"
  artifacts:
    paths: [bandit-output.json]
    when: always

integration:
  stage: integration
  script:
    - echo "This is an integration step"

prod:
  stage: prod
  script:
    - echo "This is a deploy step."
```

Before we commit this file to the repository, We need to set DOJO_HOST and DOJO_API_TOKEN under secrets variables by visiting the following URL

Gitlab Variables URL: https://gitlab-ce-XqiHnDZ0.lab.practical-devsecops.training/root/django-nv/-/settings/ci_cd

- Key: DOJO_HOST
- Value: dojo-XqiHnDZ0.lab.practical-devsecops.training
>
- Key: DOJO_API_TOKEN
- Value: Find it at https://dojo-XqiHnDZ0.lab.practical-devsecops.training/api/key-v2

Once you’re done with the variables, you can commit the .gitlab-ci.yml file and see the results of this pipeline by visiting https://gitlab-ce-XqiHnDZ0.lab.practical-devsecops.training/root/django-nv/pipelines.

Click on the appropriate job name to view its output.

The pipeline will fail because the job sast didn’t succeed. If you look at the job’s output, you’ll notice that we didn’t upload the upload-results.py file to the repository. As a result, the CI system couldn’t find this file and failed the build.

Let’s move to the next page to add this script to the repository using the Git command line. We’ll perform these steps from the DevSecOps-Box.

Upload python script in CI/CD pipeline
----------

Before we can push the upload-results.py file to the repo, we need to set up the git command line.

Initial git setup
----------

To work with git repositories, we first need to set up a username and email. We can use git config commands to set it up

Download/clone/copy the repository
----------

## Initial git setup
To work with git repositories, we first need to set up a username and email. We can use git config commands to set it up.

We can use the git clone command to download the django.nv git repository to our local machine.
```
git config --global user.email "student@practical-devsecops.com"
git config --global user.name "student"
```
```
git clone http://root:pdso-training@gitlab-ce-p30jrhut.lab.practical-devsecops.training/root/django-nv.git

OR

git clone git@gitlab-ce-p30jrhut:root/django-nv.git 
```
> Authentication Confirmation Required
> If you encounter the following prompt while trying to clone GitLab, please type yes and press Enter to proceed:
> By cloning the above repository, we created a local copy of the remote repository.
```
The authenticity of host 'gitlab-ce-p30jrhut (10.x.x.x)' can't be established.
ECDSA key fingerprint is SHA256:U1W8wQm8tgHmuF/T0uf1jNVCzHyhqeJ4MmGG/K4XmcI.
Are you sure you want to continue connecting (yes/no/[fingerprint])?
```


Lets cd into this repository to explore its content.

```
cd django-nv
```

Add a file to the repository
-----------

First, lets download the upload-results.py script using the following curl command.

```
curl https://gitlab.practical-devsecops.training/-/snippets/28/raw -o upload-results.py
git add upload-results.py
git commit -m "Add upload-results.py file"
```

Push the changes to the repository
----------

Git is a decentralized source code management system, which means all changes remain in your local git repository until you push them to the server. You can think of it this way: git was designed to work even without internet connectivity, whether you’re on flights, ships, or in remote locations like jungles__.

Since we have internet connectivity, let’s push our changes to the remote git repository using the git push command.

```
git push origin master

Counting objects: 3, done.
Delta compression using up to 8 threads.
Compressing objects: 100% (3/3), done.
Writing objects: 100% (3/3), 1.37 KiB | 1.37 MiB/s, done.
Total 3 (delta 1), reused 0 (delta 0)
To http://gitlab-ce-p30jrhut.lab.practical-devsecops.training/root/django-nv.git
   577b30f..b0324c0  main -> main

```

As discussed earlier, any change to the repository triggers the pipeline. You can see the results of this change in the pipeline tab of GitLab CI by visiting https://gitlab-ce-p30jrhut.lab.practical-devsecops.training/root/django-nv/pipelines.

Great! Now, every time a developer makes a change, our Static Application Security Testing (SAST) scanner will automatically run and upload the results to the vulnerability management system. This process ensures continuous security monitoring of our codebase.

You can verify the issues were uploaded successfully by visiting the dojo website.

Challenge: Upload ZAP Results to DefectDojo Automatically via CI/CD Pipeline
----------------------------------------------------------------

In this exercise, you will use the upload-results.py script to upload the ZAP scan results to DefectDojo through the CI/CD pipeline.

As usual, you’ll first test your solution locally in the provided terminal before integrating it into the CI/CD pipeline.
1. Use the terminal provided on the right to scan the production machine `ttps://prod-p30jrhut.lab.practical-devsecops.training` in DevSecOps Box with the help of the ZAP docker image `softwaresecurityproject/zap-stable:2.14.0` and save the result at `/django-nv/zap-output.xml`
```
docker run --user $(id -u):$(id -g) -w /zap -v $(pwd):/zap/wrk:rw\
       --rm softwaresecurityproject/zap-stable:2.14.0 zap-baseline.py\
       -t https://prod-p30jrhut.lab.practical-devsecops.training\
       -d -x zap-output.xml
```
2. After you store the ZAP scan results, please upload the result manually to Defect Dojo using the terminal on the right
```
export API_KEY=$(curl -s -XPOST -H 'content-type: application/json' https://dojo-p30jrhut.lab.practical-devsecops.training/api/v2/api-token-auth/ -d '{"username": "root", "password": "pdso-training"}' | jq -r '.token' )

python3 upload-results.py --host dojo-p30jrhut.lab.practical-devsecops.training \
    --api_key $API_KEY --engagement_id 1 --product_id 1 \
    --lead_id 1 --environment "Production" \
    --result_file /django-nv/zap-output.xml \
    --scanner "ZAP Scan"
```

3. Please update the .gitlab-ci.yml file and add the upload-results.py as part of the ZAP Scan in the CI/CD pipeline inside the after_script attribute

Add the below example dast-zap job in .gitlab-ci.yml
Ensure you set appropriate environment variables in the CI/CD system before trying the below solution.
```
dast-zap:
  stage: integration
  before_script:
    - apk add py-pip py-requests
    - docker pull softwaresecurityproject/zap-stable:2.14.0
  script:
    - docker run --user $(id -u):$(id -g) -w /zap -v $(pwd):/zap/wrk:rw --rm softwaresecurityproject/zap-stable:2.14.0 zap-baseline.py -t https://prod-p30jrhut.lab.practical-devsecops.training -d -x zap-output.xml
  after_script:
    - python3 upload-results.py --host $DOJO_HOST --api_key $DOJO_API_TOKEN --engagement_id 1 --product_id 1 --lead_id 1 --environment "Production" --result_file zap-output.xml --scanner "ZAP Scan"
  artifacts:
    paths: [zap-output.xml]
    when: always
    expire_in: 1 day
```







<br><br><br><br><br><br><br><br><br><br>

1. Scan the production machine https://prod-XqiHnDZ0.lab.practical-devsecops.training with the help of the ZAP docker image
2. Store the ZAP scan results in a file and upload the security issues to Defect Dojo
3. Embed this upload script as part of the ZAP Scan in the CI/CD pipeline using after_script task

> Please do not forget to share the answer (a screenshot and the YML file) with our staff via Slack Direct Message (DM).

Hint
----------

https://defectdojo.readthedocs.io/en/latest/integrations.html

Answer
----------
1. all answer

```
image: docker:latest

services:
  - docker:dind

stages:
  - build
  - test
  - release
  - preprod
  - integration
  - prod

build:
  stage: build
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py check

test:
  stage: test
  image: python:3.6
  before_script:
   - pip3 install --upgrade virtualenv
  script:
   - virtualenv env
   - source env/bin/activate
   - pip install -r requirements.txt
   - python manage.py test taskManager

sast:
  stage: build
  before_script:
    - apk add py-pip
  script:
    - docker pull hysnsec/bandit  # Download bandit docker container
    - docker run --user $(id -u):$(id -g) -w /zap -v $(pwd):/zap/wrk:rw --rm owasp/zap2docker-stable zap-baseline.py -t https://prod-XqiHnDZ0.lab.practical-devsecops.training -x zap-output.xml
  after_script:
    - python3 upload-results.py --host $DOJO_HOST --api_key $DOJO_API_TOKEN --engagement_id 1 --product_id 1 --lead_id 1 --environment "Production" --result_file zap-output.xml --scanner "ZAP Scan"
  artifacts:
    paths: [zap-output.xml]
    when: always

integration:
  stage: integration
  script:
    - echo "This is an integration step"

prod:
  stage: prod
  script:
    - echo "This is a deploy step."

```
